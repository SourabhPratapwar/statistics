{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "language_info": {"name": "python"}
  },
  "cells": [
    {"cell_type":"markdown","metadata":{},"source":[
      "# Statistics for ML — FAANG-Level Lab\n",
      "\n",
      "**Goal:** Confidence intervals, hypothesis testing, and interpretation for ML engineering.\n",
      "\n",
      "**Outcome:** You can quantify uncertainty and avoid p-value traps.\n"
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "import numpy as np\n",
      "\n",
      "def check(name: str, cond: bool):\n",
      "    if not cond:\n",
      "        raise AssertionError(f'Failed: {name}')\n",
      "    print(f'OK: {name}')\n",
      "\n",
      "rng = np.random.default_rng(0)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "## Section 1 — Estimators (Mean/Variance)\n",
      "\n",
      "### Task 1.1: Unbiased sample variance\n",
      "Implement sample mean and unbiased sample variance (ddof=1) without calling np.var(..., ddof=1).\n",
      "\n",
      "# HINT:\n",
      "- mean = sum(x)/n\n",
      "- unbiased var = sum((x-mean)^2)/(n-1)\n",
      "\n",
      "**Explain:** Why divide by (n-1) instead of n?"
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "def sample_mean(x):\n",
      "    # TODO\n",
      "    ...\n",
      "\n",
      "def sample_var_unbiased(x):\n",
      "    # TODO\n",
      "    ...\n",
      "\n",
      "x = rng.standard_normal(1000)\n",
      "m = sample_mean(x)\n",
      "v = sample_var_unbiased(x)\n",
      "check('mean_close', abs(m - x.mean()) < 1e-10)\n",
      "check('var_close', abs(v - x.var(ddof=1)) < 1e-8)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "## Section 2 — Confidence Interval for Mean (Normal approx)\n",
      "\n",
      "### Task 2.1: 95% CI for mean\n",
      "Compute a 95% CI for mean using normal approximation:\n",
      "CI = mean ± z * s/sqrt(n), where z≈1.96.\n",
      "\n",
      "# HINT:\n",
      "- Use unbiased sample std\n",
      "\n",
      "**FAANG gotcha:** CI is about the mean, not individual outcomes."
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "def mean_ci_normal(x, alpha=0.05):\n",
      "    # TODO: return (lo, hi)\n",
      "    ...\n",
      "\n",
      "x = rng.normal(loc=2.0, scale=3.0, size=500)\n",
      "lo, hi = mean_ci_normal(x)\n",
      "print('CI', (lo, hi), 'mean', x.mean())\n",
      "check('order', lo < x.mean() < hi)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "### Task 2.2: Coverage simulation\n",
      "Simulate repeated sampling from Normal(mu=0, sigma=1).\n",
      "Estimate how often 95% CI contains true mean.\n",
      "\n",
      "# HINT:\n",
      "- Run many trials\n",
      "- Count coverage\n",
      "\n",
      "**Explain:** Why isn't coverage exactly 0.95 in finite simulation?"
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "def estimate_ci_coverage(trials=2000, n=50):\n",
      "    # TODO\n",
      "    ...\n",
      "\n",
      "cov = estimate_ci_coverage(trials=2000, n=50)\n",
      "print('coverage', cov)\n",
      "check('reasonable', 0.92 < cov < 0.98)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "## Section 3 — Hypothesis Testing (Two-sample test intuition)\n",
      "\n",
      "### Task 3.1: Permutation test for A/B (no scipy)\n",
      "Given samples A and B, test whether mean(B) - mean(A) is significant via permutation.\n",
      "\n",
      "# HINT:\n",
      "- Combine samples\n",
      "- Shuffle and split\n",
      "- Compute diff distribution\n",
      "- p-value = fraction of diffs >= observed (two-sided if needed)\n",
      "\n",
      "**FAANG gotcha:** p-value is not P(H0 true)."
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "def permutation_pvalue(A, B, n_perm=5000, two_sided=True):\n",
      "    # TODO\n",
      "    ...\n",
      "\n",
      "A = rng.normal(0.0, 1.0, size=200)\n",
      "B = rng.normal(0.2, 1.0, size=200)\n",
      "p = permutation_pvalue(A, B, n_perm=2000)\n",
      "print('p-value', p)\n",
      "check('p_range', 0 <= p <= 1)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "## Section 4 — Multiple Comparisons (Gotcha)\n",
      "\n",
      "### Task 4.1: Bonferroni correction\n",
      "If you run m tests at alpha=0.05, Bonferroni uses alpha/m per test.\n",
      "\n",
      "Compute adjusted alpha for m=20 and explain why this matters in feature slicing / metric dashboards.\n"
    ]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[
      "m = 20\n",
      "alpha = 0.05\n",
      "# TODO\n",
      "alpha_adj = ...\n",
      "print('alpha_adj', alpha_adj)\n",
      "check('alpha_adj', abs(alpha_adj - 0.0025) < 1e-12)"
    ]},

    {"cell_type":"markdown","metadata":{},"source":[
      "---\n",
      "## Submission Checklist\n",
      "- All TODOs completed\n",
      "- Checks pass\n",
      "- Explain prompts answered\n"
    ]}
  ]
}
